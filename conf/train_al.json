{
  "task_info":{
    "label_type": "multi_label",
    "hierarchical": false,
    "hierar_taxonomy": "data/bibtex/bibtex.taxonomy",
    "hierar_penalty": 0.000001
  },
  "al_info":{
    "acq_batchsize": 50,
    "query_strategy": "rand",
    "initial_label_size": 100,
    "max_acq_label_size": 550,
    "ensemble_model_seed": 1234,
    "cl_method": "kmean",
    "val_info": {
      "reducevalopt": true,
      "valsize": 1000,
      "val_seed": 100
    },
    "exp_seed": 100,
    "dynamicsvalopt": false,
    "retrainopt": false,
    "emsemble_info":{
      "emopt": true,
      "emsemble_num": 5,
      "emsemble_method": "deep_en",
      "emsemble_dropout": 0.01
    },
    "elr_info":{
      "xprime": 100,
      "topT":0.5,
      "alpha": 0.1,
      "xpsplit": 10,
      "c_wmocu": 1,
      "beta": 1.0
    },
    "cont_train":{
      "contopt": false,
      "acqIdx": 0
    },
    "train_logit_save" :{
      "opt": false,
      "train_logits": false,
      "train_standard_labels": false
    }  
  },
  "early_stopping": false,
  "early_stopping_patience": 7,
  "early_stopping_verbose": true, 
  "full_train": false,
  "device": "cuda",
  "taskname": "bibtex",
  "model_name": "TextCNN",
  "checkpoint_dir": "checkpoint_dir_bibtex",
  "al_output_dir": "savedALresults",
  "model_dir": "trained_model_bibtex",
  "data": {
    "train_json_files": [
      "data/bibtex/bibtex_train.json"
    ],
    "validate_json_files": [
      "data/bibtex/bibtex_dev.json"
    ],
    "test_json_files": [
      "data/bibtex/bibtex_test.json"
    ],
    "generate_dict_using_json_files": true,
    "generate_dict_using_all_json_files": true,
    "generate_dict_using_pretrained_embedding": false,
    "generate_hierarchy_label": true,
    "dict_dir": "dict_bibtex",
    "num_worker": 4
  },
  "feature": {
    "feature_names": [
      "token"
    ],
    "min_token_count": 2,
    "min_char_count": 2,
    "token_ngram": 0,
    "min_token_ngram_count": 0,
    "min_keyword_count": 0,
    "min_topic_count": 2,
    "max_token_dict_size": 1000000,
    "max_char_dict_size": 150000,
    "max_token_ngram_dict_size": 10000000,
    "max_keyword_dict_size": 100,
    "max_topic_dict_size": 100,
    "max_token_len": 256,
    "max_char_len": 1024,
    "max_char_len_per_token": 4,
    "token_pretrained_file": "",
    "keyword_pretrained_file": ""
  },
  "train": {
    "batch_size": 16,
    "start_epoch": 1,
    "num_epochs": 80,
    "num_epochs_static_embedding": 0,
    "decay_steps": 1000,
    "decay_rate": 1.0,
    "clip_gradients": 100.0,
    "l2_lambda": 0.0,
    "loss_type": "BCEWithLogitsLoss",
    "sampler": "fixed",
    "num_sampled": 5,
    "visible_device_list": "0",
    "hidden_layer_dropout": 0.5
  },
  "embedding": {
    "type": "embedding",
    "dimension": 64,
    "region_embedding_type": "context_word",
    "region_size": 5,
    "initializer": "uniform",
    "fan_mode": "FAN_IN",
    "uniform_bound": 0.25,
    "random_stddev": 0.01,
    "dropout": 0.0
  },
  "optimizer": {
    "optimizer_type": "Adam",
    "learning_rate": 0.008,
    "adadelta_decay_rate": 0.95,
    "adadelta_epsilon": 1e-08
  },
  "TextCNN": {
    "kernel_sizes": [
      2,
      3,
      4
    ],
    "num_kernels": 100,
    "top_k_max_pooling": 1
  },
  "TextRNN": {
    "hidden_dimension": 64,
    "rnn_type": "GRU",
    "num_layers": 1,
    "doc_embedding_type": "Attention",
    "attention_dimension": 16,
    "bidirectional": true
  },
  "DRNN": {
    "hidden_dimension": 5,
    "window_size": 3,
    "rnn_type": "GRU",
    "bidirectional": true,
    "cell_hidden_dropout": 0.1
  },
  "eval": {
    "text_file": "data/bibtex/bibtex_test.json",
    "threshold": 0.5,
    "dir": "eval_dir",
    "batch_size": 16,
    "is_flat": true,
    "top_k": 100,
    "model_dir": "checkpoint_dir_bibtex/TextCNN_best"
  },
  "TextVDCNN": {
    "vdcnn_depth": 9,
    "top_k_max_pooling": 8
  },
  "DPCNN": {
    "kernel_size": 3,
    "pooling_stride": 2,
    "num_kernels": 16,
    "blocks": 2
  },
  "TextRCNN": {
    "kernel_sizes": [
        2,
        3,
        4
    ],
    "num_kernels": 100,
    "top_k_max_pooling": 1,
    "hidden_dimension":64,
    "rnn_type": "GRU",
    "num_layers": 1,
    "bidirectional": true
  },
  "Transformer": {
    "d_inner": 128,
    "d_k": 32,
    "d_v": 32,
    "n_head": 4,
    "n_layers": 1,
    "dropout": 0.1,
    "use_star": true
  },
  "AttentiveConvNet": {
    "attention_type": "bilinear",
    "margin_size": 3,
    "type": "advanced",
    "hidden_size": 64
  },
  "HMCN": {
    "hierarchical_depth": [0, 384, 384, 384, 384],
    "global2local": [0, 16, 192, 512, 64]
  },
  "log": {
    "logger_file": "log_test_bibtex_hierar",
    "log_level": "warn"
  },
  "bert": {
    "pretrained_model_name": "bert-base-cased",
    "max_seq_len": 256,
    "return_token_type_ids": true,
    "truncation": true,
    "padding": "longest",
    "gradient_accumulation_steps": 1,
    "linear_lr": 0.01,
    "bert_lr": 0.00005,
    "eps": 0.00000001
  }
}
